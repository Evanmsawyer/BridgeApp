
# Data Explanation

## Data Sources

All data was sourced from the [Vugraph Project](http://www.sarantakos.com/bridge/vugraph/), a community archive of contract bridge tournaments from 1955 to 2016.
The source data is in the .lin format, which is a proprietary file format that stores play-by-play information for a segment in a bridge tournament.

## Scraping Process

The data was scraped from the Vugraph Project's website using the Python script crawler.py, which uses the beautifulsoup and requests libraries in addition to 
a few of Python's builtin libraries to traverse all pages in the website's hierarchy and download any pages that end in .lin. This process resulted in ~12,000
discrete lin files. Many of these files describe games that are out of the scope of this project, which we discuss in the cleaning process section.

## Cleaning Process

After being scraped, the data was cleaned using the Python script linparser.py, which imports parser_classes.py as a module. linparser.py takes a list of lin
files and/or directories as arguments, and creates/appends the records generated by those lin files to the appropriate csv files. If no arguments are specified, 
linparser.py will parse all lin files in the current directory. The csv files generated by linparser.py all directly correlate to a table of the same name in 
the finished database. The csv files generated are board.csv, hand.csv, player.csv, plays_table.csv, round.csv, table.csv, team.csv, and trick.csv. Of the 
~12,000 input lin files obtained by crawler.py, ~6,000 were rejected by linparser.py because of formatting errors.

## File Hierarchy

The CSVs folder contains all of the CSVs generated by linparser.py. These CSVs

## Required Python Libraries

The following Python libraries are required 